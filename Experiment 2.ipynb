{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.datasets import CIFAR10\n",
    "import pytorch_lightning as pl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class CReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CReLU, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu\n",
    "        out = torch.cat((out(x), out(-x)), dim=1)\n",
    "        return out\n",
    "\n",
    "class PGLU(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, kernel_size=1, padding=0, pool=False):\n",
    "        super(PGLU, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels_in, channels_out, kernel_size, padding=padding)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2) if pool else None\n",
    "\n",
    "    def forward(self, gate, output):\n",
    "        gate = self.conv(gate)\n",
    "        if self.pool is not None:\n",
    "            gate = self.pool(gate)\n",
    "        gate = self.relu(gate)\n",
    "        gate = gate > 0\n",
    "        return output * gate\n",
    "\n",
    "class OGLU(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=1, padding=0):\n",
    "        super(OGLU, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels, channels, kernel_size, padding=padding)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, output):\n",
    "        gate = self.conv(output)\n",
    "        gate = self.relu(gate)\n",
    "        gate = gate > 0\n",
    "        return output * gate\n",
    "\n",
    "class APGLU(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, kernel_size=1, padding=0, pool=False):\n",
    "        super(APGLU, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels_in, channels_out, kernel_size, padding=padding)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.pool = nn.MaxPool2d(2, 2) if pool else None\n",
    "\n",
    "    def forward(self, gate, output):\n",
    "        gate = self.conv(gate)\n",
    "        if self.pool is not None:\n",
    "            gate = self.pool(gate)\n",
    "        gate = self.sigmoid(gate)\n",
    "        return output * gate\n",
    "\n",
    "class AOGLU(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=1, padding=0):\n",
    "        super(AOGLU, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels, channels, kernel_size, padding=padding)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, output):\n",
    "        gate = self.conv(output)\n",
    "        gate = self.sigmoid(gate)\n",
    "        return output * gate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Net(pl.LightningModule):\n",
    "    def __init__(self, lr=3e-4,\n",
    "                 act=[nn.ReLU(), nn.ReLU(), nn.ReLU(), nn.ReLU()]):\n",
    "        super(Net, self).__init__()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.act1 = act[0]\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.act2 = act[1]\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.act3 = act[2]\n",
    "        self.d3 = nn.Dropout(0.2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.act4 = act[3]\n",
    "        self.d4 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*2*2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.pool1(out)\n",
    "        out = self.bn1(out)\n",
    "        if isinstance(self.act1, PGLU) or isinstance(self.act1, APGLU):\n",
    "            out = self.act1(x, out)\n",
    "        else:\n",
    "            out = self.act1(out)\n",
    "        out2 = self.d1(out)\n",
    "\n",
    "        out = self.conv2(out2)\n",
    "        out = self.pool2(out)\n",
    "        out = self.bn2(out)\n",
    "        if isinstance(self.act2, PGLU) or isinstance(self.act2, APGLU):\n",
    "            out = self.act2(out2, out)\n",
    "        else:\n",
    "            out = self.act2(out)\n",
    "        out3 = self.d2(out)\n",
    "\n",
    "        out = self.conv3(out3)\n",
    "        out = self.pool3(out)\n",
    "        out = self.bn3(out)\n",
    "        if isinstance(self.act3, PGLU) or isinstance(self.act3, APGLU):\n",
    "            out = self.act3(out3, out)\n",
    "        else:\n",
    "            out = self.act3(out)\n",
    "        out4 = self.d3(out)\n",
    "\n",
    "        out = self.conv4(out4)\n",
    "        out = self.pool4(out)\n",
    "        out = self.bn4(out)\n",
    "        if isinstance(self.act4, PGLU) or isinstance(self.act4, APGLU):\n",
    "            out = self.act4(out4, out)\n",
    "        else:\n",
    "            out = self.act4(out)\n",
    "        out = self.d4(out)\n",
    "\n",
    "        out = out.view(-1, 256*2*2)\n",
    "        out = self.fc1(out)\n",
    "        out = self.d1(out)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor()), batch_size=25000, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor()), batch_size=10000, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor()), batch_size=10000, shuffle=False)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        accuracy = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "        self.log('val_acc', accuracy, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name  | Type        | Params\n",
      "---------------------------------------\n",
      "0  | conv1 | Conv2d      | 2.4 K \n",
      "1  | pool1 | MaxPool2d   | 0     \n",
      "2  | bn1   | BatchNorm2d | 64    \n",
      "3  | act1  | OGLU        | 1.1 K \n",
      "4  | d1    | Dropout     | 0     \n",
      "5  | conv2 | Conv2d      | 51.3 K\n",
      "6  | pool2 | MaxPool2d   | 0     \n",
      "7  | bn2   | BatchNorm2d | 128   \n",
      "8  | act2  | OGLU        | 4.2 K \n",
      "9  | d2    | Dropout     | 0     \n",
      "10 | conv3 | Conv2d      | 73.9 K\n",
      "11 | pool3 | MaxPool2d   | 0     \n",
      "12 | bn3   | BatchNorm2d | 256   \n",
      "13 | act3  | OGLU        | 16.5 K\n",
      "14 | d3    | Dropout     | 0     \n",
      "15 | conv4 | Conv2d      | 295 K \n",
      "16 | pool4 | MaxPool2d   | 0     \n",
      "17 | bn4   | BatchNorm2d | 512   \n",
      "18 | act4  | OGLU        | 65.8 K\n",
      "19 | d4    | Dropout     | 0     \n",
      "20 | fc1   | Linear      | 10.2 K\n",
      "---------------------------------------\n",
      "521 K     Trainable params\n",
      "0         Non-trainable params\n",
      "521 K     Total params\n",
      "2.086     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Blake Projects\\Transformer-Experiments\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Blake Projects\\Transformer-Experiments\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "E:\\Blake Projects\\Transformer-Experiments\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "net = Net(act=[OGLU(32), OGLU(64), OGLU(128), OGLU(256)])\n",
    "trainer = pl.Trainer(accelerator='gpu', max_epochs=256, accumulate_grad_batches=2, enable_progress_bar=False)\n",
    "trainer.fit(net)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_accuracy = trainer.callback_metrics['val_acc'].max()\n",
    "print(max_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}